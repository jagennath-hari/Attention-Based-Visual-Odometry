# Attention-Based-Visual-Odometry

In this project, we are developing a novel artificial neural network model that can be used to calculate visual odometry. The proposed model is a temporal-based attention neural network, which means that it takes into account the temporal relationship between different data points while making predictions. The architecture of the proposed model consists of several key components. First, the model takes in raw pixel and depth values from a stereo camera and uses these inputs to generate feature vectors. These feature vectors contain important information about the objects and scenes that the camera is capturing. The model then stores a history of the generated feature vectors, which allows it to take into account the temporal relationship between the current and past data points. 

Next, the model uses a technique called temporal attention to incorporate the relevant information from the history of feature vectors with the current features. This allows the model to focus on the most important information and ignore irrelevant or noisy data. The resulting output of the model is a prediction of the odometry value, which represents the movement of the camera or object. 

The proposed model has been tested in a variety of scenarios and has shown robust performance in unknown and cluttered environments. Additionally, the use of temporal attention makes the model resilient to noise, bias, blur, and occlusions in the sensor signals, which can be common sources of error in visual odometry calculations. The model was trained on 7 different scenes, using datasets that included both camera depth measurements and camera images.
